{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54a4980-d3b7-4664-9035-4abcb92b1ab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "342bee2d-d6d8-49aa-98ba-79a38ade4175",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 06:33:03.023303: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-28 06:33:03.023339: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/thema/miniconda3/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from commando import ComManDo\n",
    "from commando.evaluation import *\n",
    "from commando.utilities import predict_nn, predict_knn\n",
    "import matplotlib.pyplot as plt\n",
    "from mmd_wrapper import mmd_combine\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b783aa-276a-4064-bcfb-767f22c9fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e327b245-c736-4b3a-a99c-88eb78cd4db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thema/miniconda3/lib/python3.9/site-packages/anndata/compat/__init__.py:180: FutureWarning: Moving element from .uns['neighbors']['distances'] to .obsp['distances'].\n",
      "\n",
      "This is where adjacency matrices should go now.\n",
      "  warn(\n",
      "/home/thema/miniconda3/lib/python3.9/site-packages/anndata/compat/__init__.py:180: FutureWarning: Moving element from .uns['neighbors']['connectivities'] to .obsp['connectivities'].\n",
      "\n",
      "This is where adjacency matrices should go now.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "babel_dir = '../babel_data/DM_rep4/'\n",
    "train = sc.read_h5ad(babel_dir + 'train_rna.h5ad')\n",
    "v = train.var_names\n",
    "train = train.X.toarray()\n",
    "valid = sc.read_h5ad(babel_dir + 'truth_rna.h5ad').X.toarray()\n",
    "data1 = np.concatenate([train, valid], axis=0)\n",
    "fnames1 = np.array(v)\n",
    "\n",
    "train = sc.read_h5ad(babel_dir + 'train_atac.h5ad')\n",
    "v = train.var_names\n",
    "train = train.X.toarray()\n",
    "valid = sc.read_h5ad(babel_dir + 'truth_atac.h5ad').X.toarray()\n",
    "data2 = np.concatenate([train, valid], axis=0)\n",
    "fnames2 = np.array(v)\n",
    "\n",
    "split = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6206e91-f09d-4d3b-81b1-461ea9c57df2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thema/miniconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:235: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/home/thema/miniconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:254: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/home/thema/miniconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:235: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/home/thema/miniconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:254: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'DM_rep4'\n",
    "modality_names = ['RNA', 'ATAC']\n",
    "\n",
    "# data1 = PCA(n_components=32).fit_transform(data1)\n",
    "# data2 = PCA(n_components=32).fit_transform(data2)\n",
    "# fnames1 = fnames2 = None\n",
    "\n",
    "type1 = np.array(len(data1) * ['Cell Type 0'])\n",
    "type2 = np.array(len(data2) * ['Cell Type 0'])\n",
    "\n",
    "# Sampling\n",
    "# sample_num = 500\n",
    "# data_col_idx = np.random.choice(range(split), sample_num, replace=False)\n",
    "# data1, data2, type1, type2 = (x[list(data_col_idx) + list(range(split, len(data1)))] for x in (data1, data2, type1, type2))\n",
    "# split = sample_num\n",
    "\n",
    "# Labels\n",
    "labels = [type1, type2]\n",
    "features = [np.array(fnames1), np.array(fnames2)]\n",
    "\n",
    "# Utility\n",
    "positivize = lambda X: [x + x.min() for x in X]\n",
    "minmax = lambda X: [(x + x.min()) for x in X]\n",
    "\n",
    "# Preprocessing\n",
    "data1 = preprocessing.scale(data1, axis=0)\n",
    "data2 = preprocessing.scale(data2, axis=0)\n",
    "data1[np.isnan(data1)] = 0  # Replace NaN with average\n",
    "data2[np.isnan(data2)] = 0\n",
    "data1 = preprocessing.MinMaxScaler().fit_transform(data1)\n",
    "data2 = preprocessing.MinMaxScaler().fit_transform(data2)\n",
    "dataset = [data1, data2]\n",
    "\n",
    "# Replace NULL feature names\n",
    "for i in range(len(features)):\n",
    "    if features[i] is None:\n",
    "        features[i] = [f'Feature {i}' for i in range(dataset[i].shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "345ddc2f-d91f-474f-a3cd-13bf503cf7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Imputation\n",
    "train_idx = np.array(list(range(split)))\n",
    "test_idx = np.array(list(set(range(len(data1))) - set(train_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d40f5b92-3092-45a2-9988-073b09a6b63b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reduced Priors\n",
    "full_priors = np.eye(len(dataset[0]))\n",
    "\n",
    "random_idx = np.random.choice(range(len(dataset[0])), int(.5 * len(dataset[0])), replace=False)\n",
    "priors = np.zeros(len(dataset[0]))\n",
    "priors[random_idx] = 1\n",
    "half_priors = np.diag(priors)\n",
    "\n",
    "none_priors = np.zeros((len(dataset[0]), len(dataset[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a7c3bf-2963-4800-b804-b610133527c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dim = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5025270b-1844-4edc-888a-3e1af9ad9c0e",
   "metadata": {},
   "source": [
    "# ComManDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84dd4788-3465-4459-b48b-38e98393f976",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Integration\n",
    "kwargs = {\n",
    "    'output_dim': reduced_dim,\n",
    "    'epoch_DNN': 10000,\n",
    "    'log_DNN': 500,\n",
    "    'use_early_stop': False,\n",
    "    'batch_size': 256,\n",
    "    'pca_dim': 2*[512],\n",
    "    'dist_method': 'euclidean',\n",
    "    'loss_weights': [1,1,1,1],\n",
    "}\n",
    "fromChar = [' ', '),', '(', ')', ',', '\\'', '[', ']']\n",
    "toChar = ['', '--', '', '', '-', '', '(', ')']\n",
    "kwargs_str = str(sorted(kwargs.items()))[1:-1]\n",
    "for f, t in zip(fromChar, toChar):\n",
    "    kwargs_str = kwargs_str.replace(f, t)\n",
    "hash_str = '---'.join([dataset_name, '-'.join([str(s) for s in dataset[0].shape]), '-'.join([str(s) for s in dataset[1].shape]), kwargs_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8216cf8b-d364-4320-acbe-778c9a85218d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use random seed: 666\n",
      "Shape of Raw data\n",
      "Dataset 0: (3877, 34861)\n",
      "Dataset 1: (3877, 85596)\n",
      "Device: cpu\n",
      "---------------------------------\n",
      "Find correspondence between Dataset 1 and Dataset 2\n",
      "epoch:[500/2000] err:2.8908 alpha:0.7862\n",
      "epoch:[1000/2000] err:0.0001 alpha:0.0000\n",
      "epoch:[1500/2000] err:0.0000 alpha:0.0000\n",
      "epoch:[2000/2000] err:0.0000 alpha:0.0000\n",
      "Finished Matching!\n",
      "---------------------------------\n",
      "Train coupled autoencoders\n",
      "KL: 0.1941  Rec: 0.1096  CosSim: 13.5832  F: 2793.1545\n",
      "KL: 298.2800  Rec: 0.0422  CosSim: 173.8350  F: 58061640.0000\n",
      "KL: 79.5704  Rec: 0.0307  CosSim: 79.0115  F: 5278087.5000\n",
      "KL: 0.5201  Rec: 0.0284  CosSim: 18.5677  F: 208384.3750\n",
      "KL: 598.3115  Rec: 0.0268  CosSim: 281.2822  F: 315838080.0000\n",
      "epoch:[500/2500]: loss:227173520.000000\n",
      "KL: 3679.9314  Rec: 0.0275  CosSim: 600.2449  F: 1720022016.0000\n",
      "KL: 369.4284  Rec: 0.0272  CosSim: 104.9685  F: 36063372.0000\n",
      "KL: 1102.0284  Rec: 0.0270  CosSim: 138.1712  F: 15477174.0000\n",
      "KL: 1300.7084  Rec: 0.0267  CosSim: 126.4756  F: 45550940.0000\n",
      "KL: 1121.8380  Rec: 0.0276  CosSim: 280.8804  F: 292844352.0000\n",
      "epoch:[1000/2500]: loss:419579552.000000\n",
      "KL: 4364.4331  Rec: 0.0276  CosSim: 94.8418  F: 25921096.0000\n",
      "KL: 666.2793  Rec: 0.0270  CosSim: 143.1233  F: 70750112.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24410/55151943.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# raise FileNotFoundError()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcm_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loaded model \\'{model_str}\\''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/nck/repos/nmacom/commando/commando.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved_models/cm_im---DM_rep4---4301-34861---4301-85596---batch_size-1024--dist_method-euclidean--epoch_DNN-2500--log_DNN-500--loss_weights-(1-1-1-1)--output_dim-32--pca_dim-None--use_early_stop-False.h5'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24410/55151943.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loaded model \\'{model_str}\\''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcm_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mcm_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcm_imputed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcm_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodal_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/nck/repos/nmacom/commando/commando.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    189\u001b[0m                     \u001b[0mk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mmatch_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mintegrated_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject_commando\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mapping'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/nck/repos/nmacom/commando/commando.py\u001b[0m in \u001b[0;36mproject_commando\u001b[0;34m(self, W)\u001b[0m\n\u001b[1;32m    660\u001b[0m                     \u001b[0mbest_batch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0;31m# Append losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Imputation\n",
    "cm_im = ComManDo(**kwargs)  # , match_result=cm.match_result, debug=True)\n",
    "model_str = 'saved_models/cm_im---' + hash_str + '.h5'\n",
    "try:\n",
    "    # raise FileNotFoundError()\n",
    "    cm_im.load_model(model_str)\n",
    "    print(f'Loaded model \\'{model_str}\\'')\n",
    "except FileNotFoundError:\n",
    "    cm_im.fit_transform(dataset=[data1[train_idx], data2[train_idx]])\n",
    "    cm_im.save_model(model_str)\n",
    "cm_imputed = [cm_im.modal_predict(dataset[i][test_idx], i) for i in range(1, -1, -1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f5bb0a-d779-4d08-bb01-c2894d5b40ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Comparison Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d503695a-a26b-4f41-939a-023710a80450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imputation\n",
    "if True:\n",
    "    imputation_name = 'Babel'\n",
    "    bdata1 = sc.read_h5ad(babel_dir + 'atac_rna_test_preds.h5ad').X.toarray()\n",
    "    bdata2 = sc.read_h5ad(babel_dir + 'rna_atac_test_preds.h5ad').X.toarray()\n",
    "    nn_imputed = [bdata1, bdata2]\n",
    "else:\n",
    "    imputation_name = 'KNN'\n",
    "    nn_imputed = [predict_nn(torch.tensor(dataset[i][train_idx]).float(), torch.tensor(dataset[(i+1)%2][train_idx]).float(), torch.tensor(dataset[i][test_idx]).float()) for i in range(1, -1, -1)]\n",
    "imputed_data = [cm_imputed, nn_imputed][::-1]\n",
    "imputed_names = ['JAMIE', imputation_name][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de47e50-b35e-4f64-87af-5c0d50e89c66",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27cddd-5ab6-4bf7-bbe8-4c894c9e44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "style='white'\n",
    "sns.set(style=style)\n",
    "plt.rcParams.update({'font.weight': 'normal',\n",
    "                     'font.size': 18,\n",
    "                     'axes.titlesize': 'large',\n",
    "                     'axes.labelsize': 'large',\n",
    "                     'xtick.labelsize': 'small',\n",
    "                     'ytick.labelsize': 'small'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cad8c5-c6d2-4b6d-99cb-d4bd17e4ae75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plot_auroc_correlation(imputed_data, [data1[test_idx], data2[test_idx]], modality_names, index=0, names=imputed_names)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output_figures/' + dataset_name + '-Imp1.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd58786-9ce3-4697-bd91-d60118376df9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plot_auroc_correlation(imputed_data, [data1[test_idx], data2[test_idx]], modality_names, index=1, names=imputed_names)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output_figures/' + dataset_name + '-Imp2.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f0537-0a48-4ddc-84b7-742df334e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plot_distribution_alone([dataset[0][test_idx], cm_imputed[0]], 2*[labels[0][test_idx]], title=modality_names[0], fnames=2*[features[0]])\n",
    "sns.despine()\n",
    "plt.savefig('./output_figures/' + dataset_name + '-Dist1.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec3332f-cddc-49d3-b0cb-34ae6a42a455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plot_distribution_alone([dataset[1][test_idx], cm_imputed[1]], 2*[labels[1][test_idx]], title=modality_names[1], fnames=2*[features[1]])\n",
    "sns.despine()\n",
    "plt.savefig('./output_figures/' + dataset_name + '-Dist2.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e68ab2-dbe7-4a24-b009-482247d433a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cac14e9d-21e6-4ed5-821c-874187dda132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNA (Place) -> ATAC\n",
    "# ENSG00000251562 (4) -> HYLS1\n",
    "# ENSG00000251562 (4) -> HYLS1\n",
    "\n",
    "# ATAC (Place) -> RNA\n",
    "# ANKRD16 -> ENSG00000138119\n",
    "# PWWP2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672347ac-82eb-4ada-9353-37d1e32f0765",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod0, mod1 = 1, 0\n",
    "current_cm = cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7eafa0-1143-4f6d-bd7d-0521985cbc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from commando.utilities import sort_by_interest\n",
    "\n",
    "order, interest = sort_by_interest([current_cm.modal_predict(dataset[mod0], mod0), dataset[mod1]], limit=10)\n",
    "order_str = ', '.join([str(n) for n in order[:10]])\n",
    "order_names_str = ', '.join(features[mod1][order[:10]])\n",
    "print(f'Top performing features:\\n{order_names_str}\\n{order_str}')\n",
    "print()\n",
    "interest_str = ', '.join([str(n) for n in interest[:10]])\n",
    "interest_names_str = ', '.join(features[mod1][interest[:10]])\n",
    "print(f'Top interesting features:\\n{interest_names_str}\\n{interest_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28825a87-904d-49d4-96f6-eccde19b2867",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Omit one testing\n",
    "in_data = dataset[mod0].copy()\n",
    "target = interest[0]\n",
    "out_data = dataset[mod1][:, target]\n",
    "\n",
    "background = in_data.mean(0)\n",
    "logits = cm.modal_predict(in_data, mod0)[:, target]\n",
    "baseline = stats.pearsonr(logits, out_data)\n",
    "\n",
    "performance = []\n",
    "best_idx = -1\n",
    "best_perf = -np.inf\n",
    "best_str = ''\n",
    "check_best = 10\n",
    "testing_idx = np.random.choice(dataset[mod0].shape[1], int(1e3), replace=False)\n",
    "# testing_idx = np.array(range(in_data.shape[1]))\n",
    "for i, idx in enumerate(testing_idx):\n",
    "    # CLI\n",
    "    if (i+1) % check_best == 0 and len(performance) > 0:\n",
    "        best_idx = np.argmax(-np.array(performance))  # Replace one\n",
    "        best_perf = performance[best_idx]\n",
    "        best_str = features[mod0][testing_idx[best_idx]]\n",
    "    prog_str = math.floor(50*(i+1)/len(testing_idx)) * '|'\n",
    "    print(\n",
    "        f'{i+1:>{len(str(len(testing_idx)))}}/{len(testing_idx)} [{prog_str:<50}] - '\n",
    "        f'Current Best: {best_perf:.5f}, {best_str}'\n",
    "        , end='\\r')\n",
    "    \n",
    "    mod_data = in_data\n",
    "    # Replace one\n",
    "    # replace_idx = idx  # Replace one\n",
    "    replace_idx = [i!=idx for i in range(mod_data.shape[1])]  # Keep one\n",
    "    old_data = mod_data[:, replace_idx]\n",
    "    mod_data[:, replace_idx] = background[replace_idx]\n",
    "    \n",
    "    # Predict\n",
    "    logits = cm.modal_predict(mod_data, mod0)[:, target]\n",
    "    \n",
    "    # Repair\n",
    "    mod_data[:, replace_idx] = old_data\n",
    "    \n",
    "    # Record\n",
    "    corr = stats.pearsonr(logits, out_data)[0]\n",
    "    # corr = -np.sum((logits - out_data)**2)\n",
    "    if np.isnan(corr):\n",
    "        corr = -np.inf\n",
    "    performance.append(corr)\n",
    "print('\\nDone!')\n",
    "performance = np.array(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2027f06b-893a-4d6e-bed4-2002795e985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = testing_idx[np.argsort(performance)[::-1]]\n",
    "sorted_names = features[mod0][sorted_idx]\n",
    "sorted_perf = np.sort(performance)[::-1]\n",
    "target_name = features[mod1][target]\n",
    "\n",
    "display = 20\n",
    "print(f'Target {modality_names[mod1]} Feature: {target_name}')\n",
    "print(f'https://www.genecards.org/cgi-bin/carddisp.pl?gene={target_name}')\n",
    "importance = features[mod0][sorted_idx][:display]\n",
    "imp_str = ', '.join(importance)\n",
    "print(f'Important {modality_names[mod0]} Features: {imp_str}')\n",
    "for n, p in zip(importance, sorted_perf[:display]):\n",
    "    print(f'{p:.5f}: https://www.genecards.org/cgi-bin/carddisp.pl?gene={n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252cc934-6cc7-4a5c-914c-8b7dfcf5c47c",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c17ac3-3789-4079-a08f-1b687d194e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNA (Place) -> ATAC\n",
    "# ENSG00000251562 (4) -> HYLS1\n",
    "# ENSG00000251562 (4) -> HYLS1\n",
    "\n",
    "# ATAC (Place) -> RNA\n",
    "# ANKRD16 -> ENSG00000138119\n",
    "# PWWP2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0712bea-e842-4e4e-b3fc-73950c389191",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Subset for runtime\n",
    "use_subsetting = True\n",
    "subset_idx = np.random.choice(dataset[mod0].shape[1], 100, replace=False)\n",
    "background = np.mean(dataset[mod0], axis=0).reshape((1, -1))\n",
    "def take_subset(x, do=use_subsetting):\n",
    "    if not do:\n",
    "        return x\n",
    "    if len(x.shape) == 1:\n",
    "        return x[subset_idx]\n",
    "    return x[:, subset_idx]\n",
    "def reverse_subset(x, do=use_subsetting):\n",
    "    if not do:\n",
    "        return x\n",
    "    new_vec = np.concatenate(x.shape[0] * [background], axis=0)\n",
    "    new_vec[:, subset_idx] = x\n",
    "    return new_vec\n",
    "\n",
    "target_feature = interest[0]\n",
    "model = lambda x: current_cm.modal_predict(reverse_subset(x), mod0)[:, target_feature]\n",
    "data = dataset[mod0]\n",
    "back = background\n",
    "feature_names = features[mod0]\n",
    "output_names = features[mod1][target_feature]\n",
    "\n",
    "# Apply subsetting\n",
    "data = take_subset(data)\n",
    "back = take_subset(back)\n",
    "feature_names = list(take_subset(np.array(feature_names)))\n",
    "\n",
    "# Explainer\n",
    "explainer = shap.Explainer(model, back, feature_names=feature_names, output_names=output_names)\n",
    "shap_values = explainer(data, max_evals=2*data.shape[1]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746fb98e-711e-4d06-af6e-602de5eff070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display = 20\n",
    "print(f'Target {modality_names[mod1]} Feature: {output_names}')\n",
    "for n in [output_names]:\n",
    "    print(f'https://www.genecards.org/cgi-bin/carddisp.pl?gene={n}')\n",
    "importance = np.array(shap_values.feature_names)[np.argsort(shap_values.abs.mean(0).values)][::-1][:display]\n",
    "# importance = np.array(shap_values.feature_names)[np.argsort(shap_values.mean(axis=0).abs.values)[::-1][:display]]\n",
    "# importance = np.array(shap_values.feature_names)[np.argsort(shap_values.abs.max(axis=0).abs.values)[::-1][:display]]\n",
    "imp_str = ', '.join(importance)\n",
    "print(f'Important {modality_names[mod0]} Features: {imp_str}')\n",
    "for n in importance:\n",
    "    print(f'https://www.genecards.org/cgi-bin/carddisp.pl?gene={n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b037bb81-1a8b-4d0f-8684-c58d5ff11014",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "ax = plt.gcf().add_subplot(1, 1, 1)\n",
    "shap.summary_plot(shap_values, data, plot_type='violin', max_display=display, plot_size=(9.2, 5), show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output_figures/' + dataset_name + '-Summary.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6f14f4-f6d0-4f5c-a620-ce7608eb7d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "shap.plots.heatmap(shap_values, max_display=7, show=False)  # 7 because problem with visualization and tight layout\n",
    "plt.gca().set_xlabel('Samples')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output_figures/' + dataset_name + '-Heat.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a719366-2a36-431f-958d-e34a3afc1c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "ax = plt.gcf().add_subplot(1, 1, 1)\n",
    "shap.dependence_plot(np.argsort(np.abs(shap_values.values).mean(0))[::-1][0], shap_values.values, data, ax=ax, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output_figures/' + dataset_name + '-Dep1.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdeb0c1-f6ed-419a-af7b-0c3a05331827",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "ax = plt.gcf().add_subplot(1, 1, 1)\n",
    "shap.plots.waterfall(100*shap_values[0], show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output_figures/' + dataset_name + '-Waterfall1.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff934999-1ed1-432e-9ec9-5e2c6aff8b06",
   "metadata": {},
   "source": [
    "## Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fdef3f-01da-4a85-9874-4959506a270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Kernel Explainer\n",
    "# kexplainer = shap.KernelExplainer(model, shap.kmeans(data, 10), feature_names=feature_names, output_names=output_names)\n",
    "# import warnings\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter('ignore')\n",
    "#     kshap_values = kexplainer.shap_values(data, nsamples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b532500c-092f-4ae7-88f5-e0e2da8c44bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.force_plot(kexplainer.expected_value, kshap_values[0, :], data[0, :], matplotlib=True, show=False)\n",
    "# plt.savefig('./output_figures/' + dataset_name + '-Force.png', bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa8501-ca8b-4a1d-9f66-ec6f60ad2b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shap.initjs()\n",
    "# shap.force_plot(kexplainer.expected_value, kshap_values, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0fba63ad021b48298325a1944bb13b50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_456d52a5d9d443aa8eb61f183573dc03",
       "max": 300,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_667e93b1bd9e4ab3b3528ea55452b9e0",
       "tabbable": null,
       "tooltip": null,
       "value": 300
      }
     },
     "178604d53c3940169f19e91448a9b41e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "380ec8eb500142459cc2ead815aecbbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "456d52a5d9d443aa8eb61f183573dc03": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5af371d029f743fca390371395ab11cc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "667e93b1bd9e4ab3b3528ea55452b9e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "886bb3ba77594457b5c0b9c63b183273": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5af371d029f743fca390371395ab11cc",
       "placeholder": "​",
       "style": "IPY_MODEL_8cac8cf3b74b454cbf0a9f42ea0c4b4d",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "8cac8cf3b74b454cbf0a9f42ea0c4b4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a21e072787314f68bed5e94a6a6c5fe3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c7b00c38494048c5928e7d572dcf2ea8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_886bb3ba77594457b5c0b9c63b183273",
        "IPY_MODEL_0fba63ad021b48298325a1944bb13b50",
        "IPY_MODEL_ccbbe2a83c0c41da84873e182a9de78d"
       ],
       "layout": "IPY_MODEL_a21e072787314f68bed5e94a6a6c5fe3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ccbbe2a83c0c41da84873e182a9de78d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_178604d53c3940169f19e91448a9b41e",
       "placeholder": "​",
       "style": "IPY_MODEL_380ec8eb500142459cc2ead815aecbbf",
       "tabbable": null,
       "tooltip": null,
       "value": " 300/300 [00:33&lt;00:00, 10.39it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
